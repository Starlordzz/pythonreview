import pdfplumber
import chromadb
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
client_openai = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)


# === 1. å®šä¹‰è¯»å– PDF çš„å‡½æ•° (çœ¼ç›) ===
def extract_text_from_pdf(pdf_path):
    print(f"ğŸ“– æ­£åœ¨è¯»å– {pdf_path} ...")
    full_text = ""
    # æ‰“å¼€ PDF æ–‡ä»¶
    with pdfplumber.open(pdf_path) as pdf:
        # éå†æ¯ä¸€é¡µ
        for page in pdf.pages:
            # æå–è¿™ä¸€é¡µçš„æ–‡å­—
            text = page.extract_text()
            if text:
                full_text += text + "\n"
    return full_text


# === 2. å®šä¹‰åˆ‡ç‰‡å‡½æ•° (åˆ‡é¦™è‚ ) ===
# è¿™æ˜¯ä¸€ä¸ªç®€å•çš„åˆ‡æ³•ï¼šæ¯ 300 ä¸ªå­—åˆ‡ä¸€åˆ€
# ä»¥åç”¨äº† LangChainï¼Œå®ƒæœ‰æ›´é«˜çº§çš„åˆ‡æ³•ï¼ˆæ¯”å¦‚æŒ‰å¥å·åˆ‡ï¼‰
def split_text(text, chunk_size=300):
    chunks = []
    # range(å¼€å§‹, ç»“æŸ, æ­¥é•¿)
    for i in range(0, len(text), chunk_size):
        # æˆªå–ä» i åˆ° i+300 çš„æ–‡å­—
        chunk = text[i: i + chunk_size]
        chunks.append(chunk)
    return chunks


# === 3. åµŒå…¥å‡½æ•° (è¿˜æ˜¯é‚£ä¸ªé…æ–¹) ===
def get_embedding(text):
    return client_openai.embeddings.create(
        model="text-embedding-v1",
        input=text
    ).data[0].embedding


# === ä¸»ç¨‹åº ===
if __name__ == "__main__":
    # A. å‡†å¤‡å·¥ä½œ
    pdf_filename = "data.pdf"  # âš ï¸ ç¡®ä¿ä½ æ”¾äº†è¿™ä¸ªæ–‡ä»¶ï¼

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œé˜²æ­¢æŠ¥é”™
    if not os.path.exists(pdf_filename):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° {pdf_filename}ï¼Œè¯·æŠŠæ–‡ä»¶æ”¾è¿›é¡¹ç›®æ–‡ä»¶å¤¹ï¼")
        exit()

    # B. è¯»å–ä¸åˆ‡ç‰‡
    raw_text = extract_text_from_pdf(pdf_filename)
    print(f"âœ… è¯»å–æˆåŠŸï¼å…± {len(raw_text)} ä¸ªå­—ã€‚")

    chunks = split_text(raw_text, chunk_size=300)
    print(f"ğŸ”ª åˆ‡ç‰‡å®Œæˆï¼å…±åˆ‡æˆäº† {len(chunks)} æ®µã€‚")

    # C. å­˜å…¥æ•°æ®åº“
    print("ğŸš€ æ­£åœ¨å­˜å…¥ ChromaDB...")

    chroma_client = chromadb.PersistentClient(path="./my_knowledge_db")

    # ä¸ºäº†é¿å… ID å†²çªï¼Œæˆ‘ä»¬è¿™æ¬¡æ–°å»ºä¸€ä¸ª collection å« 'pdf_data'
    # å¦‚æœå·²å­˜åœ¨å…ˆåˆ é™¤ï¼ˆæ–¹ä¾¿ä½ åå¤æµ‹è¯•ï¼‰
    try:
        chroma_client.delete_collection("pdf_data")
    except:
        pass

    collection = chroma_client.create_collection(name="pdf_data")

    # æ‰¹é‡è®¡ç®—å‘é‡å¹¶å­˜å‚¨
    # æ³¨æ„ï¼šå¦‚æœ PDF å¾ˆå¤§ï¼Œè¿™é‡Œå¯èƒ½è¦è·‘ä¸€ä¼šå„¿
    ids = [f"chunk_{i}" for i in range(len(chunks))]
    embeddings = [get_embedding(chunk) for chunk in chunks]

    collection.add(
        documents=chunks,
        embeddings=embeddings,
        ids=ids
    )

    print("ğŸ‰ å…¨éƒ¨å®Œæˆï¼ä½ çš„ PDF å·²ç»è¢« AI è®°ä½äº†ã€‚")