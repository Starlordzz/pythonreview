import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()
client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# === 1. æ¨¡æ‹Ÿä¼ä¸šæµ·é‡çŸ¥è¯†åº“ ===
# æƒ³è±¡è¿™é‡Œæœ‰ 1000 æ¡æ•°æ®
knowledge_base = [
    "å…¬å¸çš„WIFIå¯†ç æ˜¯: 12345678ã€‚",
    "è¡Œæ”¿éƒ¨åœ¨3æ¥¼ï¼ŒæŠ€æœ¯éƒ¨åœ¨4æ¥¼ï¼Œè´¢åŠ¡éƒ¨åœ¨5æ¥¼ã€‚",
    "æŠ¥é”€æµç¨‹ï¼šå…ˆå¡«å•å­ï¼Œæ‰¾ä¸»ç®¡ç­¾å­—ï¼Œæœ€åå»è´¢åŠ¡éƒ¨ã€‚",
    "è€æ¿æœ€è®¨åŒåˆ«äººè¿Ÿåˆ°ï¼Œè¿Ÿåˆ°ä¸€æ¬¡æ‰£500å—ã€‚",
    "å…¬å¸çš„åˆä¼‘æ—¶é—´æ˜¯ 12:00 åˆ° 13:30ã€‚"
]

# ç¼“å­˜æ‰€æœ‰çŸ¥è¯†åº“çš„å‘é‡ (çœŸå®é¡¹ç›®ä¸­ï¼Œè¿™ä¸€æ­¥ä¼šå­˜åˆ°æ•°æ®åº“é‡Œï¼Œä¸éœ€è¦æ¯æ¬¡éƒ½ç®—)
print("ğŸ“š æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼• (åˆå§‹åŒ–)...")
kb_vectors = [client.embeddings.create(model="text-embedding-v3", input=doc).data[0].embedding for doc in
              knowledge_base]
print("âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼")


def search_relevant_doc(query):
    """ å»çŸ¥è¯†åº“é‡Œææœ€ç›¸å…³çš„ä¸€æ¡ """
    # 1. æŠŠé—®é¢˜å˜å‘é‡
    query_vec = client.embeddings.create(model="text-embedding-v3", input=query).data[0].embedding
    print(query_vec)
    # 2. ç®—åˆ†
    scores = cosine_similarity([query_vec], kb_vectors)[0]
    print(scores)
    # 3. æ‰¾åˆ°æœ€é«˜åˆ†çš„ç´¢å¼•
    best_idx = np.argmax(scores)

    # 4. åªæœ‰å½“åˆ†æ•°å¤Ÿé«˜ï¼ˆæ¯”å¦‚å¤§äº 0.4ï¼‰æ‰ç®—æ‰¾åˆ°ï¼Œå¦åˆ™ç®—æ²¡æ‰¾åˆ°
    if scores[best_idx] < 0.4:
        return None

    return knowledge_base[best_idx]


# === ä¸»ç¨‹åº ===
while True:
    user_query = input("\nè¯·æé—® (è¾“å…¥ q é€€å‡º): ")
    if user_query == 'q': break

    # Step 1: æ£€ç´¢ (Retrieve)
    print(f"ğŸ” æ­£åœ¨çŸ¥è¯†åº“ä¸­æœç´¢ç­”æ¡ˆ...")
    found_doc = search_relevant_doc(user_query)

    if found_doc:
        print(f"ğŸ“– æ£€ç´¢åˆ°çš„å‚è€ƒèµ„æ–™: {found_doc}")
        # Step 2: å¢å¼º (Augment) & ç”Ÿæˆ (Generate)
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¼ä¸šåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸‹é¢çš„ã€å†…éƒ¨èµ„æ–™ã€‘å›ç­”å‘˜å·¥é—®é¢˜ã€‚

        ã€å†…éƒ¨èµ„æ–™ã€‘ï¼š
        {found_doc}

        ã€å‘˜å·¥é—®é¢˜ã€‘ï¼š
        {user_query}
        """
    else:
        print("âš ï¸ çŸ¥è¯†åº“é‡Œæ²¡æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œä¾é  AI è‡ªèº«çŸ¥è¯†å›ç­”ã€‚")
        prompt = user_query

    # Step 3: è°ƒç”¨å¤§æ¨¡å‹
    completion = client.chat.completions.create(
        model="qwen-plus",
        messages=[{"role": "user", "content": prompt}]
    )

    print(f"ğŸ¤– AI å›ç­”: {completion.choices[0].message.content}")